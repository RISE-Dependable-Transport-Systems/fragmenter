# ============================================================================
# fragmenter Configuration
# ============================================================================
# Copy this file to .env and fill in your API keys
# All configuration can be overridden via environment variables or CLI arguments

# ============================================================================
# API Keys
# ============================================================================

# OpenAI API Key (required for OpenAI provider)
OPENAI_API_KEY=sk-your-openai-api-key-here

# Anthropic API Key (required for Anthropic provider)
# ANTHROPIC_API_KEY=sk-ant-your-anthropic-api-key-here

# HuggingFace API Key (optional, required for some HF models)
# HUGGINGFACEHUB_API_TOKEN=hf-your-huggingface-token-here

# ============================================================================
# LLM Configuration
# ============================================================================

# LLM Provider: openai, ollama, anthropic, huggingface
LLM_PROVIDER=openai

# LLM Model Name (provider-specific)
# OpenAI:
#   Find available models at: https://platform.openai.com/docs/models
# Anthropic:
#   Find available models at: https://platform.claude.com/docs/en/about-claude/models/overview
# Ollama (locally hosted, must be pulled first):
#   Find available models at: https://ollama.com/library
# HuggingFace (requires sufficient GPU/RAM):
#   Find available models at: https://huggingface.co/models?pipeline_tag=text-generation
LLM_MODEL=gpt-4o

# LLM Temperature (0.0 = deterministic, 1.0 = creative)
LLM_TEMPERATURE=0.1

# LLM Max Tokens (maximum response length)
# For code generation:
#   - 512: Small snippets (25-40 lines)
#   - 2048: Medium functions (100-160 lines)
#   - 4096: Large functions/classes (200-320 lines)
#   - 8192: Multiple classes/files (400-640 lines)
#   - 16384: Very long files (800-1280 lines)
# Note: Higher values = more cost per request
LLM_MAX_TOKENS=8192

# Ollama Base URL (only for ollama provider)
# OLLAMA_BASE_URL=http://localhost:11434

# ============================================================================
# Embedding Model Configuration
# ============================================================================

# Embedding Provider: openai, huggingface, ollama
EMBED_PROVIDER=openai

# Embedding Model Name (provider-specific)
# OpenAI: https://platform.openai.com/docs/models
# HuggingFace: https://huggingface.co/models?other=embeddings
# Ollama: https://ollama.com/search?c=embedding
EMBED_MODEL=text-embedding-3-small
